{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"V28","authorship_tag":"ABX9TyMEaFB3o+g5QHtO7bD+DjZZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"x7LBfh0uLpup","colab":{"base_uri":"https://localhost:8080/"},"outputId":"bd35955a-f93e-402a-a0ba-bd5cce75825d","executionInfo":{"status":"ok","timestamp":1733797606058,"user_tz":-420,"elapsed":20896,"user":{"displayName":"Xuân Trần","userId":"16348586452814696727"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HOc-mgrK5B_6"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","import numpy as np\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","import pickle as cPickle\n","import pandas as pd\n","from keras.callbacks import EarlyStopping\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.preprocessing import LabelBinarizer\n","from keras.layers import LSTM, Dense, TimeDistributed, Bidirectional\n","import sklearn.metrics\n","from sklearn.metrics import confusion_matrix\n","\n","from sklearn.model_selection import KFold\n","from keras.models import Sequential\n","from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n","\n","from tensorflow.keras import Model\n","from keras.layers import Dense,Embedding,LSTM,Dropout,Bidirectional\n","from keras import models"]},{"cell_type":"code","source":["path_data = \"/content/drive/MyDrive/SuccKD_MultiSpecies/Data/\"\n","path_model = \"/content/drive/MyDrive/SuccKD_MultiSpecies/Model/\"\n","path_result = \"/content/drive/MyDrive/SuccKD_MultiSpecies/Result/\""],"metadata":{"id":"J_IWpbzwTR2r"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CUUYvlp8Lpup"},"outputs":[],"source":["# Buildi an amino acid dictionary\n","def twoTupleDic1():\n","    AA_list_sort = ['G','A','V','L','I','M','P','F','W','S','T','N','Q','Y','C','K','R','H','D','E','X']\n","\n","    AA_dict = {}\n","    numm = 1\n","    for i in AA_list_sort:\n","        AA_dict[i] = numm\n","        numm += 1\n","    return AA_dict\n","def ProSentence(pro, K):\n","\tsentence = \"\"\n","\tlength = len(pro)\n","\tfor i in range(length - K + 1):\n","\t\tsentence += pro[i: i + K] + \" \"\n","    #delete extra space\n","\tsentence = sentence[0 : len(sentence) - 1]\n","\treturn sentence\n","k =1#1-gram\n","word_index1 = twoTupleDic1()\n","vocab_size = len(word_index1)\n"]},{"cell_type":"code","source":["# Load Train data\n","file_train = \"Train_Generic_succ.csv\"\n","df_train =pd.read_csv(path_data +file_train, delimiter= ',')\n","\n","texts_train =[] #PTMsequend kmer\n","for i in df_train['Peptide_WS_33']:\n","  temp = ProSentence(i,k) # Biểu diễn dữ liệu đầu vào thành token Kmer\n","  texts_train.append(temp)\n","df_train['k_mer'] =texts_train\n","train_sequences = []\n","for each in texts_train:\n","    each_index_list = []\n","    each = each.split(' ')\n","    for i in each:\n","        each_index_list.append(word_index1[i])\n","    train_sequences.append(each_index_list)\n","# Tokenizer train data\n","data_token = []\n","for i in df_train['k_mer']:\n","   data_token.append(i.split())\n","\n","MAX_SEQUENCE_LENGTH = len(data_token[1])\n","\n","Xtrain= pad_sequences(train_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n","ytrain = np.array(df_train['Label'])\n","Xtrain.shape\n","ytrain = np.array(ytrain)\n","\n","# perform one-hot encoding on the labels\n","lb = LabelBinarizer()\n","ytrain = lb.fit_transform(ytrain)\n","ytrain = to_categorical(ytrain)\n","ytrain.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vIUl99_-Cgwq","executionInfo":{"status":"ok","timestamp":1733797634429,"user_tz":-420,"elapsed":622,"user":{"displayName":"Xuân Trần","userId":"16348586452814696727"}},"outputId":"29c0da0e-878a-4b2f-b309-4184d01495e8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(14250, 2)"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o0BeJLTXLpus","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4bbab6f6-1bb9-41e4-ce67-866245dc51de","executionInfo":{"status":"ok","timestamp":1733797644303,"user_tz":-420,"elapsed":457,"user":{"displayName":"Xuân Trần","userId":"16348586452814696727"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3231, 2)"]},"metadata":{},"execution_count":9}],"source":["# load test data\n","file_test =\"Test_Generic_succ.csv\"\n","df_test =pd.read_csv(path_data+file_test,delimiter= ',')\n","text_test =[] #PTMsequend kmer\n","for i in df_test['Peptide_WS_33']:\n","  temp = ProSentence(i,k) # Biểu diễn dữ liệu đầu vào thành token Kmer\n","  text_test.append(temp)\n","df_test['k_mer'] =text_test\n","\n","test_sequences = []\n","for each in text_test:\n","    each_index_list = []\n","    each = each.split(' ')\n","    for i in each:\n","        each_index_list.append(word_index1[i])\n","    test_sequences.append(each_index_list)\n","\n","Xtest = pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n","ytest= np.array(df_test['Label'])\n","Xtest.shape\n","ytest = np.array(ytest)\n","# perform one-hot encoding on the labels\n","lb = LabelBinarizer()\n","ytest= lb.fit_transform(ytest)\n","ytest = to_categorical(ytest)\n","ytest.shape"]},{"cell_type":"code","source":["TIME_STEPS = MAX_SEQUENCE_LENGTH\n","INPUT_SIZE =300"],"metadata":{"id":"2rVtp9A3R3n4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**KD2_Succi: 2teacher and 1 student**"],"metadata":{"id":"j8iyq7NWccJp"}},{"cell_type":"code","source":["# 2 teacher and 1 student\n","import tensorflow as tf\n","from tensorflow.keras import optimizers\n","from tensorflow.keras import models, layers, losses\n","\n","# Teacher 1\n","def create_cnn_model():\n","    model = models.Sequential()\n","    model.add(layers.Embedding(vocab_size+1, 300, input_length=MAX_SEQUENCE_LENGTH,trainable=True))\n","    model.add(layers.Dropout(0.4))\n","    model.add(layers.Conv1D(filters=32, kernel_size=3, activation='relu', padding='same'))\n","    model.add(layers.MaxPooling1D(2))\n","    model.add(layers.Dropout(0.4))\n","    model.add(layers.BatchNormalization())\n","    model.add(layers.Conv1D(filters=32, kernel_size=3, activation='relu'))\n","    model.add(layers.MaxPooling1D(pool_size=2))\n","    model.add(layers.Flatten())\n","    model.add(layers.Dropout(0.4))\n","    model.add(layers.Dense(64, activation='relu'))\n","    model.add(layers.Dense(2, activation='softmax'))  # Binary classification (softmax for distillation)\n","    return model\n","\n","# Teacher 2\n","def create_bilstm_model():\n","    model = models.Sequential()\n","    model.add(layers.Embedding(vocab_size+1, 300, input_length=MAX_SEQUENCE_LENGTH,trainable=True))\n","    model.add(layers.Bidirectional(layers.LSTM(units=32, return_sequences=True), input_shape=(TIME_STEPS, INPUT_SIZE)))\n","    model.add(layers.BatchNormalization())\n","    model.add(layers.Dropout(0.2))\n","    model.add(layers.Bidirectional(layers.LSTM(units=32, return_sequences=True), input_shape=(TIME_STEPS, INPUT_SIZE)))\n","    model.add(layers.BatchNormalization())\n","    model.add(layers.Flatten())\n","    model.add(layers.Dropout(0.4))\n","    model.add(layers.Dense(64, activation='relu'))\n","    model.add(layers.Dense(2, activation='softmax'))  # Binary classification (softmax for distillation)\n","    return model\n","# Student\n","def create_student():\n","    model = models.Sequential()\n","    model.add(layers.Embedding(vocab_size+1, 300, input_length=MAX_SEQUENCE_LENGTH,trainable=True))\n","    model.add(layers.Conv1D(filters=32, kernel_size=3, activation='relu', padding='same'))\n","    model.add(layers.MaxPooling1D(2))\n","    model.add(layers.Dropout(0.2))\n","    model.add(layers.Bidirectional(layers.LSTM(units=32, return_sequences=True), input_shape=(TIME_STEPS, INPUT_SIZE)))\n","    model.add(layers.Flatten())\n","    model.add(layers.Dropout(0.4))\n","    model.add(layers.Dense(64, activation='relu'))\n","    model.add(layers.Dense(2, activation='softmax'))  # Binary classification (softmax for distillation)\n","    return model\n","# KD2_Succi: Knowlege Distiller Model\n","import tensorflow as tf\n","from tensorflow.keras import optimizers\n","\n","class Distiller(tf.keras.Model):\n","    def __init__(self, teacher1, teacher2, student, alpha=0.5, temperature=3.0):\n","        super(Distiller, self).__init__()\n","        self.teacher1 = teacher1\n","        self.teacher2 = teacher2\n","        self.student = student\n","        self.alpha = alpha\n","        self.temperature = temperature\n","\n","        # Optimizer for the student\n","        self.student_optimizer = AdamW(learning_rate=0.0001)\n","\n","    def compile(self, metrics, student_loss_fn, distillation_loss_fn):\n","        super(Distiller, self).compile(metrics=metrics)\n","        self.student_loss_fn = student_loss_fn\n","        self.distillation_loss_fn = distillation_loss_fn\n","\n","    def call(self, inputs):\n","        \"\"\"\n","        This method defines how the model processes inputs.\n","        Args:\n","        - inputs: Input data (Xtest_student or any other data).\n","\n","        Returns:\n","        - Output logits from the student model.\n","        \"\"\"\n","        student_logits = self.student(inputs, training=False)\n","        return student_logits\n","\n","    def train_step(self, data):\n","        x, y = data\n","\n","        # Sequentially forward pass through teachers\n","        teacher1_logits = self.teacher1(x, training=False)\n","        teacher2_logits = self.teacher2(x, training=False)\n","\n","        with tf.GradientTape() as tape:\n","            # Forward pass through student\n","            student_logits = self.student(x, training=True)\n","\n","            # Compute the task loss (for hard labels)\n","            student_loss = self.student_loss_fn(y, student_logits)\n","\n","            # Compute distillation losses (for soft labels)\n","            distill_loss1 = self.distillation_loss_fn(\n","                tf.nn.softmax(teacher1_logits / self.temperature, axis=1),\n","                tf.nn.softmax(student_logits / self.temperature, axis=1)\n","            ) * (self.temperature ** 2)\n","\n","            distill_loss2 = self.distillation_loss_fn(\n","                tf.nn.softmax(teacher2_logits / self.temperature, axis=1),\n","                tf.nn.softmax(student_logits / self.temperature, axis=1)\n","            ) * (self.temperature ** 2)\n","\n","            # Combined loss\n","            total_loss = self.alpha * student_loss + (1 - self.alpha) * (distill_loss1 + distill_loss2)\n","\n","        # Compute gradients and update student model\n","        grads = tape.gradient(total_loss, self.student.trainable_variables)\n","        self.student_optimizer.apply_gradients(zip(grads, self.student.trainable_variables))\n","\n","        # Update metrics for the student\n","        self.compiled_metrics.update_state(y, student_logits)\n","\n","        # Return results\n","        results = {\n","            'student_loss': student_loss,\n","            'distill_loss1': distill_loss1,\n","            'distill_loss2': distill_loss2\n","        }\n","        results.update({m.name: m.result() for m in self.metrics})\n","        return results\n","\n","    def test_step(self, data):\n","        x, y = data\n","        student_logits = self.student(x, training=False)\n","\n","        # Compute the task loss (for hard labels)\n","        student_loss = self.student_loss_fn(y, student_logits)\n","\n","        # Update metrics for the student\n","        self.compiled_metrics.update_state(y, student_logits)\n","\n","        return {\n","            'student_loss': student_loss,\n","            **{m.name: m.result() for m in self.metrics}\n","        }\n","\n","# Instantiate models\n","\n","teacher1 = create_cnn_model()\n","teacher2 = create_bilstm_model()\n","student = create_student()\n","teacher1.compile(\n","    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n","    metrics=[\n","        \"categorical_accuracy\",\n","        \"AUC\",\n","    ],\n","    optimizer=keras.optimizers.AdamW(learning_rate=0.0001),\n",")\n","teacher2.compile(\n","    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n","    metrics=[\n","        \"categorical_accuracy\",\n","        \"AUC\",\n","    ],\n","    optimizer=keras.optimizers.AdamW(learning_rate=0.0001),\n",")\n","teacher1.fit(\n","    Xtrain, ytrain,\n","    batch_size =16,\n","    epochs=50\n",")\n","teacher1.save(path_model +\"model_teacher21.h5\")\n","\n","teacher2.fit(\n","    Xtrain, ytrain,\n","    batch_size =16,\n","    epochs=50\n",")\n","teacher2.save(path_model +\"model_teacher22.h5\")\n"],"metadata":{"id":"_vMySVxTcXF-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730886648069,"user_tz":-420,"elapsed":1440886,"user":{"displayName":"Xuân Trần","userId":"16348586452814696727"}},"outputId":"2842a0ea-dde8-4e3b-8d71-26e9a0180319"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - AUC: 0.6266 - categorical_accuracy: 0.5967 - loss: 0.7345\n","Epoch 2/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - AUC: 0.6666 - categorical_accuracy: 0.6459 - loss: 0.6628\n","Epoch 3/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - AUC: 0.6855 - categorical_accuracy: 0.6552 - loss: 0.6425\n","Epoch 4/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - AUC: 0.6945 - categorical_accuracy: 0.6606 - loss: 0.6353\n","Epoch 5/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - AUC: 0.7060 - categorical_accuracy: 0.6683 - loss: 0.6278\n","Epoch 6/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - AUC: 0.7216 - categorical_accuracy: 0.6725 - loss: 0.6161\n","Epoch 7/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - AUC: 0.7332 - categorical_accuracy: 0.6726 - loss: 0.6067\n","Epoch 8/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - AUC: 0.7299 - categorical_accuracy: 0.6746 - loss: 0.6089\n","Epoch 9/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - AUC: 0.7441 - categorical_accuracy: 0.6858 - loss: 0.5990\n","Epoch 10/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - AUC: 0.7498 - categorical_accuracy: 0.6827 - loss: 0.5927\n","Epoch 11/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - AUC: 0.7628 - categorical_accuracy: 0.6990 - loss: 0.5813\n","Epoch 12/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - AUC: 0.7652 - categorical_accuracy: 0.6930 - loss: 0.5788\n","Epoch 13/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - AUC: 0.7605 - categorical_accuracy: 0.6954 - loss: 0.5837\n","Epoch 14/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - AUC: 0.7733 - categorical_accuracy: 0.7032 - loss: 0.5717\n","Epoch 15/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - AUC: 0.7752 - categorical_accuracy: 0.7119 - loss: 0.5690\n","Epoch 16/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - AUC: 0.7810 - categorical_accuracy: 0.7101 - loss: 0.5628\n","Epoch 17/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - AUC: 0.7848 - categorical_accuracy: 0.7108 - loss: 0.5595\n","Epoch 18/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - AUC: 0.7868 - categorical_accuracy: 0.7135 - loss: 0.5563\n","Epoch 19/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - AUC: 0.7864 - categorical_accuracy: 0.7188 - loss: 0.5584\n","Epoch 20/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - AUC: 0.7965 - categorical_accuracy: 0.7143 - loss: 0.5454\n","Epoch 21/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - AUC: 0.7927 - categorical_accuracy: 0.7195 - loss: 0.5501\n","Epoch 22/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - AUC: 0.7955 - categorical_accuracy: 0.7186 - loss: 0.5463\n","Epoch 23/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - AUC: 0.8028 - categorical_accuracy: 0.7248 - loss: 0.5378\n","Epoch 24/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - AUC: 0.8057 - categorical_accuracy: 0.7276 - loss: 0.5354\n","Epoch 25/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - AUC: 0.8037 - categorical_accuracy: 0.7267 - loss: 0.5368\n","Epoch 26/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - AUC: 0.8092 - categorical_accuracy: 0.7323 - loss: 0.5327\n","Epoch 27/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - AUC: 0.8020 - categorical_accuracy: 0.7255 - loss: 0.5402\n","Epoch 28/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - AUC: 0.8087 - categorical_accuracy: 0.7331 - loss: 0.5324\n","Epoch 29/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - AUC: 0.8160 - categorical_accuracy: 0.7348 - loss: 0.5226\n","Epoch 30/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - AUC: 0.8123 - categorical_accuracy: 0.7333 - loss: 0.5280\n","Epoch 31/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - AUC: 0.8168 - categorical_accuracy: 0.7378 - loss: 0.5217\n","Epoch 32/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - AUC: 0.8211 - categorical_accuracy: 0.7450 - loss: 0.5184\n","Epoch 33/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - AUC: 0.8145 - categorical_accuracy: 0.7349 - loss: 0.5262\n","Epoch 34/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - AUC: 0.8204 - categorical_accuracy: 0.7400 - loss: 0.5178\n","Epoch 35/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - AUC: 0.8191 - categorical_accuracy: 0.7365 - loss: 0.5185\n","Epoch 36/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - AUC: 0.8271 - categorical_accuracy: 0.7414 - loss: 0.5097\n","Epoch 37/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - AUC: 0.8210 - categorical_accuracy: 0.7382 - loss: 0.5167\n","Epoch 38/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - AUC: 0.8214 - categorical_accuracy: 0.7378 - loss: 0.5158\n","Epoch 39/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - AUC: 0.8261 - categorical_accuracy: 0.7426 - loss: 0.5090\n","Epoch 40/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - AUC: 0.8275 - categorical_accuracy: 0.7480 - loss: 0.5089\n","Epoch 41/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - AUC: 0.8325 - categorical_accuracy: 0.7497 - loss: 0.5013\n","Epoch 42/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - AUC: 0.8288 - categorical_accuracy: 0.7467 - loss: 0.5062\n","Epoch 43/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - AUC: 0.8257 - categorical_accuracy: 0.7414 - loss: 0.5105\n","Epoch 44/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - AUC: 0.8337 - categorical_accuracy: 0.7555 - loss: 0.5013\n","Epoch 45/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - AUC: 0.8289 - categorical_accuracy: 0.7500 - loss: 0.5064\n","Epoch 46/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - AUC: 0.8320 - categorical_accuracy: 0.7486 - loss: 0.5025\n","Epoch 47/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - AUC: 0.8320 - categorical_accuracy: 0.7483 - loss: 0.5011\n","Epoch 48/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - AUC: 0.8355 - categorical_accuracy: 0.7528 - loss: 0.4985\n","Epoch 49/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - AUC: 0.8219 - categorical_accuracy: 0.7350 - loss: 0.5153\n","Epoch 50/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - AUC: 0.8405 - categorical_accuracy: 0.7600 - loss: 0.4925\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 26ms/step - AUC: 0.6317 - categorical_accuracy: 0.6004 - loss: 0.8517\n","Epoch 2/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 26ms/step - AUC: 0.7456 - categorical_accuracy: 0.6816 - loss: 0.5960\n","Epoch 3/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 26ms/step - AUC: 0.7804 - categorical_accuracy: 0.6996 - loss: 0.5590\n","Epoch 4/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 26ms/step - AUC: 0.8008 - categorical_accuracy: 0.7165 - loss: 0.5348\n","Epoch 5/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 26ms/step - AUC: 0.8185 - categorical_accuracy: 0.7369 - loss: 0.5190\n","Epoch 6/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 26ms/step - AUC: 0.8142 - categorical_accuracy: 0.7330 - loss: 0.5224\n","Epoch 7/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 27ms/step - AUC: 0.8391 - categorical_accuracy: 0.7509 - loss: 0.4899\n","Epoch 8/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 27ms/step - AUC: 0.8353 - categorical_accuracy: 0.7504 - loss: 0.4949\n","Epoch 9/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 26ms/step - AUC: 0.8474 - categorical_accuracy: 0.7590 - loss: 0.4801\n","Epoch 10/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 27ms/step - AUC: 0.8497 - categorical_accuracy: 0.7615 - loss: 0.4771\n","Epoch 11/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 26ms/step - AUC: 0.8558 - categorical_accuracy: 0.7755 - loss: 0.4712\n","Epoch 12/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 26ms/step - AUC: 0.8649 - categorical_accuracy: 0.7776 - loss: 0.4537\n","Epoch 13/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 26ms/step - AUC: 0.8705 - categorical_accuracy: 0.7803 - loss: 0.4450\n","Epoch 14/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 26ms/step - AUC: 0.8699 - categorical_accuracy: 0.7802 - loss: 0.4465\n","Epoch 15/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 25ms/step - AUC: 0.8796 - categorical_accuracy: 0.7922 - loss: 0.4305\n","Epoch 16/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 26ms/step - AUC: 0.8815 - categorical_accuracy: 0.7943 - loss: 0.4291\n","Epoch 17/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 25ms/step - AUC: 0.8868 - categorical_accuracy: 0.7983 - loss: 0.4200\n","Epoch 18/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 25ms/step - AUC: 0.8890 - categorical_accuracy: 0.7978 - loss: 0.4139\n","Epoch 19/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 25ms/step - AUC: 0.8967 - categorical_accuracy: 0.8113 - loss: 0.4040\n","Epoch 20/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 26ms/step - AUC: 0.8993 - categorical_accuracy: 0.8118 - loss: 0.3990\n","Epoch 21/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 26ms/step - AUC: 0.9031 - categorical_accuracy: 0.8153 - loss: 0.3921\n","Epoch 22/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 26ms/step - AUC: 0.9040 - categorical_accuracy: 0.8188 - loss: 0.3924\n","Epoch 23/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 25ms/step - AUC: 0.9111 - categorical_accuracy: 0.8269 - loss: 0.3780\n","Epoch 24/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 25ms/step - AUC: 0.9143 - categorical_accuracy: 0.8278 - loss: 0.3704\n","Epoch 25/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 25ms/step - AUC: 0.9184 - categorical_accuracy: 0.8345 - loss: 0.3621\n","Epoch 26/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 25ms/step - AUC: 0.9193 - categorical_accuracy: 0.8400 - loss: 0.3604\n","Epoch 27/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 26ms/step - AUC: 0.9231 - categorical_accuracy: 0.8362 - loss: 0.3508\n","Epoch 28/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 26ms/step - AUC: 0.9282 - categorical_accuracy: 0.8472 - loss: 0.3403\n","Epoch 29/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 25ms/step - AUC: 0.9310 - categorical_accuracy: 0.8501 - loss: 0.3361\n","Epoch 30/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 25ms/step - AUC: 0.9310 - categorical_accuracy: 0.8526 - loss: 0.3353\n","Epoch 31/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 25ms/step - AUC: 0.9379 - categorical_accuracy: 0.8582 - loss: 0.3172\n","Epoch 32/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 26ms/step - AUC: 0.9401 - categorical_accuracy: 0.8617 - loss: 0.3141\n","Epoch 33/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 26ms/step - AUC: 0.9390 - categorical_accuracy: 0.8601 - loss: 0.3161\n","Epoch 34/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 25ms/step - AUC: 0.9410 - categorical_accuracy: 0.8640 - loss: 0.3109\n","Epoch 35/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 25ms/step - AUC: 0.9450 - categorical_accuracy: 0.8677 - loss: 0.3004\n","Epoch 36/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 25ms/step - AUC: 0.9494 - categorical_accuracy: 0.8703 - loss: 0.2888\n","Epoch 37/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 25ms/step - AUC: 0.9530 - categorical_accuracy: 0.8800 - loss: 0.2797\n","Epoch 38/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 25ms/step - AUC: 0.9535 - categorical_accuracy: 0.8794 - loss: 0.2780\n","Epoch 39/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 26ms/step - AUC: 0.9543 - categorical_accuracy: 0.8808 - loss: 0.2742\n","Epoch 40/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 26ms/step - AUC: 0.9580 - categorical_accuracy: 0.8874 - loss: 0.2647\n","Epoch 41/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 25ms/step - AUC: 0.9598 - categorical_accuracy: 0.8899 - loss: 0.2594\n","Epoch 42/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 25ms/step - AUC: 0.9586 - categorical_accuracy: 0.8821 - loss: 0.2612\n","Epoch 43/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 25ms/step - AUC: 0.9654 - categorical_accuracy: 0.8981 - loss: 0.2416\n","Epoch 44/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 26ms/step - AUC: 0.9655 - categorical_accuracy: 0.8946 - loss: 0.2414\n","Epoch 45/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 25ms/step - AUC: 0.9676 - categorical_accuracy: 0.9016 - loss: 0.2335\n","Epoch 46/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 25ms/step - AUC: 0.9676 - categorical_accuracy: 0.9011 - loss: 0.2335\n","Epoch 47/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 25ms/step - AUC: 0.9678 - categorical_accuracy: 0.9026 - loss: 0.2319\n","Epoch 48/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 25ms/step - AUC: 0.9697 - categorical_accuracy: 0.9064 - loss: 0.2250\n","Epoch 49/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 26ms/step - AUC: 0.9711 - categorical_accuracy: 0.9086 - loss: 0.2205\n","Epoch 50/50\n","\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 26ms/step - AUC: 0.9726 - categorical_accuracy: 0.9118 - loss: 0.2144\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]}]},{"cell_type":"code","source":["from keras import models\n","from tensorflow.keras.optimizers import Adam, AdamW\n","\n","teacher_model1 = models.load_model(path_model +\"model_teacher21.h5\")\n","teacher_model2 = models.load_model(path_model +\"model_teacher22.h5\")\n","# Compile Distiller\n","distiller = Distiller(teacher1=teacher_model1, teacher2=teacher_model2, student=student, alpha=0.5, temperature=10)\n","distiller.compile(\n","    metrics=['categorical_accuracy','AUC'],\n","    student_loss_fn=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n","    distillation_loss_fn=tf.keras.losses.KLDivergence()\n",")\n","distiller.fit(Xtrain, ytrain,\n","              epochs=50,\n","              batch_size =16,\n","              )"],"metadata":{"id":"i9kHhulbR3-n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","student.save(path_model + \"KD2_Succi.h5\") # Save model KD2"],"metadata":{"id":"_Nw8qrCVb2oi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pip install openpyxl"],"metadata":{"id":"VTGEIE4O0abs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import json\n","import os  # Import os to check if the path exists\n","import pandas as pd  # Import pandas for easy CSV saving\n","from sklearn.metrics import confusion_matrix  # Import confusion_matrix\n","# Generate final predictions using logits from both students\n","ypred = student.predict(Xtest_student)\n","\n","# Ensure predictions are in the correct format\n","ypred = np.argmax(ypred, axis=1)  # Getting the predicted class\n","ytest_true = np.argmax(ytest_student, axis=1)  # Getting the true class\n","\n","# Compute the confusion matrix\n","confusion_mat = confusion_matrix(ytest_true, ypred)  # Rename to avoid overwriting\n","\n","# Calculate TP, TN, FP, FN\n","TN = confusion_mat[0, 0]  # True Negative\n","FP = confusion_mat[0, 1]  # False Positive\n","FN = confusion_mat[1, 0]  # False Negative\n","TP = confusion_mat[1, 1]  # True Positive\n","\n","# Create a DataFrame to hold TP, TN, FP, FN values\n","data = {'TP': [TP],\n","        'FP': [FP],\n","        'TN': [TN],\n","        'FN': [FN]}\n","\n","df = pd.DataFrame(data)\n","\n","# Define the path where you want to save the output file\n","# Make sure this points to a valid directory\n","output_file = 'Generic_KD2_Succi.xlsx'\n","\n","# Write the DataFrame to an Excel file\n","df.to_excel(os.path.join(path_result, output_file), index=False)\n","\n","print(f\"Các giá trị TP, TN, FP, FN đã được ghi vào file {output_file} dưới dạng cột.\")"],"metadata":{"id":"EQBaUMGmTqOY"},"execution_count":null,"outputs":[]}]}